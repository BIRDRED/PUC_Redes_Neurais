{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnLFFG6e5sug"
      },
      "source": [
        "# Pr√°tica I - Redes Neurais usando Python"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## I. Introduction\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Overview of PyTorch\n",
        "PyTorch is an open-source machine learning library for Python that was released by Facebook's AI research team. It is widely used for building and training neural networks and provides a high-level interface for building models. PyTorch is known for its dynamic computational graph, which allows for easier debugging and faster development of neural networks. It also has strong support for GPU acceleration, making it well-suited for deep learning applications."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Why Python is a good choice for PyTorch\n",
        "Python is one of the most popular programming languages for data science and machine learning. It is easy to learn, has a large and supportive community, and has many powerful libraries for scientific computing, such as NumPy, Pandas, and Matplotlib. Python's simplicity and readability make it an ideal language for writing code that is easy to understand and maintain. PyTorch is written in Python, and its API is designed to be intuitive and easy to use."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Course objectives\n",
        "The objective of this course is to provide an overview of Python programming language and its use in PyTorch. By the end of this lecture, you should have a basic understanding of Python syntax, as well as NumPy, Pandas, and PyTorch libraries. This knowledge will prepare you to write your own neural network models using PyTorch in subsequent lectures."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## II. Python Basics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Variables and Data Types\n",
        "Variables are used to store data in a program. In Python, variables can be assigned different types of data such as integers, floats, strings, and booleans. Python is dynamically typed, which means that the type of a variable is inferred at runtime based on the data assigned to it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Control Structures\n",
        "Control structures are used to control the flow of execution in a program. In Python, the if statement is used to perform a conditional test, and the for and while loops are used to repeat a block of code. The break and continue statements are used to modify the behavior of loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Functions\n",
        "Functions are blocks of code that can be reused throughout a program. In Python, functions are defined using the def keyword, followed by the function name, and the function parameters in parentheses. A function can return a value using the return keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Classes \n",
        "\n",
        "This course isn't intended to present all Python fundamentals, but `Class` will definitely help us to create a better code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thiago, 28\n",
            "Greetings, Luke. My name is Thiago\n"
          ]
        }
      ],
      "source": [
        "class Person:\n",
        "    def __init__(self, name, age):\n",
        "        self.name = name \n",
        "        self.age = age \n",
        "\n",
        "    def __str__(self):\n",
        "        return f'{self.name}, {self.age}'\n",
        "    \n",
        "    def greetings(self, visitant):\n",
        "        print(f'Greetings, {visitant}. My name is {self.name}')\n",
        "    \n",
        "person1 = Person('Thiago','28') \n",
        "print(person1)\n",
        "person1.greetings('Luke')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can heritage some objects. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thiago, 28, Neural networks\n",
            "Greetings, Luke. My name is Thiago\n"
          ]
        }
      ],
      "source": [
        "class Student(Person):\n",
        "    def __init__(self, name, age, course):\n",
        "        super().__init__(name, age)\n",
        "        self.course = course \n",
        "\n",
        "    def __str__(self):\n",
        "        return f'{self.name}, {self.age}, {self.course}' \n",
        "    \n",
        "\n",
        "student1 = Student('Thiago','28','Neural networks') \n",
        "print(student1)\n",
        "student1.greetings('Luke')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this course, we will this use this artefact in two ocasions:\n",
        "\n",
        "- Building the Neural Network \n",
        "\n",
        "- Building the torch Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Importing Libraries\n",
        "Python has a rich ecosystem of libraries that can be used for scientific computing, machine learning, and data analysis. To use a library in a program, it must be imported using the import statement. For example, the NumPy library can be imported using the statement import numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn   #Definicao da rede neural\n",
        "from torch.utils.data import Dataset, DataLoader  #utilidade para dataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## III. Pandas Basics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Introduction to Pandas\n",
        "Pandas is a Python library that provides data manipulation and analysis tools. It is built on top of NumPy and provides powerful data structures such as Series and DataFrame.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Loading Data\n",
        "Pandas provides many functions for loading data from various sources such as CSV files, Excel files, SQL databases, and JSON files. The most commonly used function is read_csv(), which can read data from a CSV file and create a DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the dataset. \n",
        "\n",
        "df = pd.read_csv()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example:\n",
        "\n",
        "In this example, we will use the Iris dataset, a common benchmark problem for Data Science pratictioners.\n",
        "The dataset contains 150 registries and 4 attributes (length and width for petals and sepals)\n",
        "\n",
        "<img src=\"https://www.embedded-robotics.com/wp-content/uploads/2022/01/Iris-Dataset-Classification.png\"/>\n",
        "\n",
        "Image source: https://www.embedded-robotics.com/iris-dataset-classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. DataFrame\n",
        "A DataFrame is a two-dimensional table-like data structure that can hold data of different types. It is similar to a spreadsheet or a database table, where each column represents a variable, and each row represents an observation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Data Cleaning\n",
        "Pandas provides many functions for cleaning and transforming data. Some common data cleaning operations include removing missing values, replacing values, and filtering rows based on conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### E. Data Exploration\n",
        "Pandas provides many functions for exploring and summarizing data. Some common data exploration operations include computing descriptive statistics, grouping data, and visualizing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IV. Data preparation with Scikit-Learn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Data split "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# using train_test_split "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Other preprocessing techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## V. PyTorch Basics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Tensors\n",
        "Tensors are the basic building blocks of PyTorch. They are similar to NumPy arrays, but with the added benefit of GPU acceleration. Tensors can be created using the torch.tensor() function, which takes a list or tuple as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([1, 2, 3]) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Operations on Tensors\n",
        "PyTorch provides many operations that can be performed on tensors, such as element-wise arithmetic, matrix multiplication, and reduction operations. PyTorch also provides many mathematical functions such as sin(), cos(), and exp(), which can be applied element-wise to a tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = torch.tensor([0, 1, 0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 2, 0])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(a) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(a)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Neural Networks\n",
        "PyTorch provides a high-level interface for building neural networks, through the torch.nn module. Neural networks can be defined as a sequence of layers, where each layer performs a specific operation on the input data. PyTorch also provides many pre-defined layers, such as convolutional layers and linear layers, that can be used to build complex networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We will use the init to initialize the network layers, and forward to define the propagation.\n",
        "\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "    \n",
        "  def forward(self,x):\n",
        "    pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Optimizers\n",
        "PyTorch provides several optimizers, such as stochastic gradient descent (SGD) and Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### E. Dataset\n",
        "In PyTorch, a dataset is an abstract class that represents a collection of data. A dataset can be used to represent any type of data, such as images, text, or audio. To use a dataset in PyTorch, we need to create a custom subclass of the torch.utils.data.Dataset class, and implement the len() and getitem() methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### F. Dataloader\n",
        "A dataloader is a PyTorch utility that allows us to efficiently load data from a dataset. The dataloader can automatically shuffle the data, batch the data into smaller groups, and load the data in parallel using multiple CPU cores. To create a dataloader in PyTorch, we need to pass a dataset object and a batch size to the torch.utils.data.DataLoader class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_loader = DataLoader(train_dataset, batch_size=32)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### G. Autograd\n",
        "PyTorch has a feature called autograd, which allows for automatic differentiation of tensors. This means that gradients can be computed automatically for tensors that are involved in a computation. This is useful for training neural networks, where gradients are used to update the weights of the network.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VI. Hands-on PyTorch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  X_test_torch = torch.from_numpy(X_test).float()\n",
        "  y_hat = model(X_test_torch)\n",
        "  y_ = torch.argmax(y_hat.data,dim = 1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=False):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_confusion_matrix(cm, data.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "RN_ex1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "d044c6e0ce06759120adefce77398d00e1228e64d92f3f185fbd024a7701b8e0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
